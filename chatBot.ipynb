{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/techalok/ML/blob/master/chatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff75gLzBauW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ml7Ze3fEdhOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numlist = [2, 23,343,545,11,33, 45 ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCCXlUamdu09",
        "colab_type": "code",
        "outputId": "c32bac52-b54b-4a64-a581-27da27920962",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dict1={'Name': 'alok', 'age':25,'gender':'male'}\n",
        "print(dict1)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Name': 'alok', 'age': 25, 'gender': 'male'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wl8VmHPFncVs",
        "colab_type": "code",
        "outputId": "b77f9ec8-be75-4d99-d741-aa237ef9e2f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "housetrain=pd.read_csv(\"d:/Alok_ML_Python/train.csv\")\n",
        "housetest=pd.read_csv(\"d:/Alok_ML_Python/test1.csv\")\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-871cca381035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhousetrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"d:/Alok_ML_Python/train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mhousetest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"d:/Alok_ML_Python/test1.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'd:/Alok_ML_Python/train.csv' does not exist: b'd:/Alok_ML_Python/train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8dOUm2FuIvS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeRFk3f9uQnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq5BAIyIuXze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuvTxG7YR0sM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gauth = GoogleAuth()\n",
        "gauth.CommandLineAuth()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbH3iGNSkDIK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty5hkBoBkIKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST96_2KCkOy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':\"1ShGidDG1N50IcRinK1G-4YPSKgi35DZJ\"})   # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('amis.csv')        # replace the file name with your file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRRoVeD8kfir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('amis.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmbMP47gkk89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.head(9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFkdrXDr6QlS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':\"15wnnxUKx_Z5NM5zz39ivEHoqWSBOxjIF\"})   # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('Churn_Modelling.csv')        # replace the file name with your file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuRXxCpV60b8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "bankchurn = pd.read_csv('Churn_Modelling.csv')\n",
        "bankchurn.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XsW8QyU9BUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KU1DqO97Asg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le=LabelEncoder()\n",
        "bankchurn.Gender=le.fit_transform(bankchurn.Gender)\n",
        "bankchurn.Geography=le.fit_transform(bankchurn.Geography)\n",
        "\n",
        "y=bankchurn.Exited\n",
        "X=bankchurn.drop('Exited', axis=1)\n",
        "#bankchurn=bankchurn.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "nn=MLPClassifier(hidden_layer_sizes=(30,30,30), activation='logistic')\n",
        "#3 hidden layers with 30 neurons per layer\n",
        "nnmodel=nn.fit(X,y)\n",
        "nnmodel.score(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIcZnBm49kp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NNpredict=nnmodel.predict(X)\n",
        "pd.crosstab(y, NNpredict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5SmFW0K99if",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GRID Search Algo\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import matplotlib.pyplot as plt\n",
        "tuned_parameters=[{'hidden_layer_sizes': [1,2,3,4,5,67,8,9,10,20,30,40], 'activation':['relu'],'alpha':[0.0001, 0.001], 'max_iter': [200,500]}]\n",
        "nngrid=GridSearchCV(MLPClassifier(), tuned_parameters, cv=3)\n",
        "nngridmodel=GridSearchCV(MLPClassifier(), tuned_parameters, cv=3)\n",
        "nngridmodel=nngrid.fit(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KABK4N41iJWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "nnreg= MLPRegressor(hidden_layer_sizes=(100, 50, 100),\n",
        "                   solver='lbfgs',\n",
        "                   max_iter=50, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PD7ZkHkyjdcX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nnregmodel=nnreg.fit(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV1cvabmjoyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nnregmodel.score=(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAuQLvVDjwNf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nnregpredict=nnregmodel.predict(X_testsplit)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtpT2QmukxKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gg-alX8k6B2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RF=RandomForestClassifier(n_estimators=2000)\n",
        "#builds 2000 trees"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7F-NypJlEcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RFmodel=RF.fit(X,y)\n",
        "RFmodel=RF.score(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPNw473wlWe-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RFpredict=RFmodel.predict(X)\n",
        "pd.crosstab(y,RFpredict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnuR1q5XluyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "X, y, test_size=0.20, random_state=123)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "X_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Mc79QPlnzWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "GB=GradientBoostingClassifier(n_estimators=1000)\n",
        "GBmodel=GB.fit(X,y)\n",
        "GBmodel.score(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vReuXbFqp2-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoof3nB7tDhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D1Tow2ltK2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fib(n):\n",
        "    a,b=0, 1\n",
        "    while a<n:\n",
        "        print(a, end=' ')\n",
        "        a, b= b, a+b\n",
        "    print()\n",
        "\n",
        "def fib2(n):\n",
        "    result=[]\n",
        "    a,b=0, 1\n",
        "    while a<n:\n",
        "        a,b=b, a+b\n",
        "    return result\n",
        "\n",
        "fib(15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcmcOEk5-ADP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Python NLP : \n",
        "# Python Regular Expression (RegEx)\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-KM7DR9nbkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Functions - search , findall, sub & split\n",
        "# Metacharacters - Character with special meaning\n",
        "# ^ - starts with\n",
        "# $ - ends with\n",
        "# \\ - signals special sequence\n",
        "# \\d - digits\n",
        "# \\s - Whitespace Chars\n",
        "# \\b - returns match where specified chars at Beginnniing or End\n",
        "#.* - Matches 0, 1 or more occurances of any char\n",
        "\n",
        "txt=\"Its both Chilly and Hot in Hyderabad\"\n",
        "print(len(txt))\n",
        "x=re.search(\"^It.*Hyderabad$\", txt) #String Search with it as Start and Hyderabad as end\n",
        "print(x)\n",
        "x=re.search(\"^It.*Hyd*\", txt) #String Search with it as Start and Hyderabad as end\n",
        "print(x)\n",
        "y=re.findall('H', txt)\n",
        "print(y)\n",
        "y=re.findall('ot', txt)\n",
        "print(y)\n",
        "z=re.split('\\s', txt)  # Splits string based on white spaces and O/P is a list\n",
        "print(z)\n",
        "u=re.findall('.', txt) # Splits string into chars\n",
        "print(u)\n",
        "\n",
        "z=re.split('\\s', txt)\n",
        "print(z)\n",
        "\n",
        "v=re.sub('\\s', '$', txt)\n",
        "print(v)\n",
        "\n",
        "u1=re.sub('\\$', 's', txt)\n",
        "print(u1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cZIvhtGupkd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 'r - read  'w' - write  'a' - append    ||  'rw' - read/write    'x' - create new file   't' - textmode  'b' - binary mode \n",
        "\n",
        "import os\n",
        "file_path=''\n",
        "filename=''\n",
        "path2file=os.path.join(file_path, filename)\n",
        "fd=open(path2file, 'r', errors='ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xQD76Viv_qE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find (name, path):\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        if name in files:\n",
        "            return os.path.join(root, name)\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNTF2zR1xMe7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "response=urllib.request.urlopen('https://en.wikipedia.org/wiki/Python_(programming_language)')\n",
        "html=response.read()\n",
        "soup=BeautifulSoup(html, \"html5lib\")\n",
        "text=soup.get_text(strip=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwGXARmxzn3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens=[t for t in text.split()] # split into words\n",
        "import nltk\n",
        "freq=nltk.FreqDist(tokens) #words frequency\n",
        "for key, val in freq.items():\n",
        "    print(str(key)+ ':' +str(val))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzRLwJZj49NA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    freq.plot(20, cumulative=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyFogekq1XC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens=[t for t in text.split()] # split into words\n",
        "import nltk\n",
        "freq=nltk.FreqDist(tokens) #words frequency\n",
        "for key, val in freq.items():\n",
        "    print(str(key)+ ':' +str(val))\n",
        "freq.plot(20, cumulative=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dOBLyrR1vaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leLOayW12HQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "freq.plot(20, cumulative=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03GKHZzK2THf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "#nltk.download('stopwords')\n",
        "clean_tokens=tokens\n",
        "for token in tokens:\n",
        "    if token in stopwords.words(\"english\"):\n",
        "        clean_tokens.remove(token)\n",
        "\n",
        "freq_clean=nltk.FreqDist(clean_tokens)\n",
        "freq_clean.plot(20, cumulative=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ca-tdj-_AyH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence=\"Google LLC is an American multinational technology company that specializes in Internet-related services and products, which include online advertising technologies, search engine, cloud computing, software, and hardware. It is considered one of the Big Four technology companies, alongside Amazon, Apple, and Facebook. Google was founded in September 1998 by Larry Page and Sergey Brin and Currently headed by Sunder Pichai\"\n",
        "sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC2yz1LjCdri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import wordpunct_tokenize, sent_tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw9srGGZCmK3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "38ad7786-8105-4070-b901-f09616b1a358"
      },
      "source": [
        "words=wordpunct_tokenize(content) \n",
        "words"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Google',\n",
              " 'LLC',\n",
              " 'is',\n",
              " 'an',\n",
              " 'American',\n",
              " 'multinational',\n",
              " 'technology',\n",
              " 'company',\n",
              " 'that',\n",
              " 'specializes',\n",
              " 'in',\n",
              " 'Internetrelated',\n",
              " 'services',\n",
              " 'and',\n",
              " 'products',\n",
              " 'which',\n",
              " 'include',\n",
              " 'online',\n",
              " 'advertising',\n",
              " 'technologies',\n",
              " 'search',\n",
              " 'engine',\n",
              " 'cloud',\n",
              " 'computing',\n",
              " 'software',\n",
              " 'and',\n",
              " 'hardware',\n",
              " 'It',\n",
              " 'is',\n",
              " 'considered',\n",
              " 'one',\n",
              " 'of',\n",
              " 'the',\n",
              " 'Big',\n",
              " 'Four',\n",
              " 'technology',\n",
              " 'companies',\n",
              " 'alongside',\n",
              " 'Amazon',\n",
              " 'Apple',\n",
              " 'and',\n",
              " 'Facebook',\n",
              " 'Google',\n",
              " 'was',\n",
              " 'founded',\n",
              " 'in',\n",
              " 'September',\n",
              " '1998',\n",
              " 'by',\n",
              " 'Larry',\n",
              " 'Page',\n",
              " 'and',\n",
              " 'Sergey',\n",
              " 'Brin',\n",
              " 'and',\n",
              " 'Currently',\n",
              " 'headed',\n",
              " 'by',\n",
              " 'Sunder',\n",
              " 'Pichai']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lF4PixPDoq5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "outputId": "58c703c1-1827-4fbf-ce6c-421818c85a26"
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"popular\")\n",
        "sentences=sent_tokenize(content)\n",
        "sentences"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Google LLC is an American multinational technology company that specializes in Internetrelated services and products which include online advertising technologies search engine cloud computing software and hardware It is considered one of the Big Four technology companies alongside Amazon Apple and Facebook Google was founded in September 1998 by Larry Page and Sergey Brin and Currently headed by Sunder Pichai']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5WoALg9NUZR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a253f133-88d7-4865-fc29-8a20b2bdbc54"
      },
      "source": [
        "#Synonyms for words\n",
        "#from nltk.stem import WordNetLemmatizer\n",
        "#from nltk.corpus.reader.wordnet import NOUN\n",
        "from nltk.corpus import wordnet\n",
        "#from nltk.compat import python_2_unicode_compatible\n",
        "import sys\n",
        "synonyms=[]\n",
        "for syn in wordnet.synsets('Computer'):\n",
        "    for lemma in syn.lemmas():\n",
        "        synonyms.append(lemma.name())\n",
        "print(synonyms)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['computer', 'computing_machine', 'computing_device', 'data_processor', 'electronic_computer', 'information_processing_system', 'calculator', 'reckoner', 'figurer', 'estimator', 'computer']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5QRgrxiNwcj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e81abc0c-34fd-4d60-dabb-011852ea1b02"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "print()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiTQHgPWOS__",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8dc41d61-7b7d-412b-e9dd-21bec5ad7482"
      },
      "source": [
        "from nltk import bigrams, trigrams\n",
        "biwords=bigrams(words)\n",
        "biwords"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object bigrams at 0x7fdd09f47ca8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w7C_O5lOyib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "triwords=trigrams(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HClkUjrO1sq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "from nltk import word_tokenize\n",
        "content=re.sub(r'[^\\w\\s]', '', content)\n",
        "words=word_tokenize(content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMsd_xSmVY60",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "897aef98-dd45-42e7-8ec0-7111894ff1fb"
      },
      "source": [
        "print(words)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Google', 'LLC', 'is', 'an', 'American', 'multinational', 'technology', 'company', 'that', 'specializes', 'in', 'Internetrelated', 'services', 'and', 'products', 'which', 'include', 'online', 'advertising', 'technologies', 'search', 'engine', 'cloud', 'computing', 'software', 'and', 'hardware', 'It', 'is', 'considered', 'one', 'of', 'the', 'Big', 'Four', 'technology', 'companies', 'alongside', 'Amazon', 'Apple', 'and', 'Facebook', 'Google', 'was', 'founded', 'in', 'September', '1998', 'by', 'Larry', 'Page', 'and', 'Sergey', 'Brin', 'and', 'Currently', 'headed', 'by', 'Sunder', 'Pichai']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMx4w-MFqoXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Greetings Input\n",
        "GREETING_INPUTS=(\"HELLO\", \"HI\", \"HEY\")\n",
        "GREETING_RESPONSES=[\"HI\", \"HELLO\", \"HEY\", \"HI THERE\"]\n",
        "def greeting(sentences):\n",
        "    for word in sentence.split():\n",
        "        if word.lower() in greeting_inputs:\n",
        "            return random.choice(GREETING_RESPONSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzztG9bFrD0r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "e02e35b0-dd62-40f0-e621-8c578c84cd64"
      },
      "source": [
        "raw=raw.lower()"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-116-d9885d86609e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'raw' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIk_aidnrYN_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "dae905f7-f1ed-48e3-c06f-0da5069cfb86"
      },
      "source": [
        "words=nltk.word_tokenize(raw)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-a4c5ddc2d779>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'raw' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnoIR6A9rcEI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "7b09ca6f-962a-4c52-8f89-a1baa54cf752"
      },
      "source": [
        "sentences=nltk.sent_tokenize(raw)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-f7cf801b9a86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'raw' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmZmvhKArh4V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b8671be0-f0d2-469b-9479-172085e47bd7"
      },
      "source": [
        "from nltk import bigrams, trigrams\n",
        "biwords=bigrams(words)\n",
        "print(biwords)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<generator object bigrams at 0x7fdd09eb0ca8>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iNwPguVsFyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fF9evDzsXx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def response(user_response):\n",
        "    robo_response=''\n",
        "    sentences.append(user_response)\n",
        "    Tfindf=TfindfVectorizer(stop_words='english')\n",
        "    Tfidff=Tfidf.fit_transform(sentences)\n",
        "    vals=cosine_similarity(ftidf[-1], tfidf)\n",
        "    idx=vals.argsort()[0][-2]\n",
        "    flat=vals.flatten()\n",
        "    flat.sort()\n",
        "    req_tfidf=flat[-2]\n",
        "\n",
        "    if(req_tfidf==0):\n",
        "        robo_response=robo_response+\"Sorry, i dont understand\"\n",
        "        return robo_response\n",
        "    else:\n",
        "        robo_response=robo_response+rentences[idx]\n",
        "        return robo_response"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSwTOLqZv7pC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "5d81a89e-bec0-46ce-a937-2e83e6aa210c"
      },
      "source": [
        "flag=True\n",
        "print(\"ROBO: Answer Queries, Want to Exit, Type Bye!\")\n",
        "while(flag==True):\n",
        "    user_response=input()\n",
        "    user_response=user_response.lower()\n",
        "    if(user_response!='bye'):\n",
        "        if(user_resonse=='thanks' or user_response=='thank you'):\n",
        "            flag=False\n",
        "            print(\"ROBO: you are welcome\")\n",
        "        else:\n",
        "            if(greeting(user_response)!=None):\n",
        "                print(\"ROBO: \"+greeting(user_response))\n",
        "            else:\n",
        "                print(\"ROBO:\" , end=\"\")\n",
        "                print(response(user_response))\n",
        "                sentences.remove(user_response)\n",
        "    else:\n",
        "        flag=False\n",
        "        print(\"ROBO: Bye!..\")"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROBO: Answer Queries, Want to Exit, Type Bye!\n",
            "hi\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-121-8234dd24ff18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0muser_response\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_response\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m'bye'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_resonse\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'thanks'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0muser_response\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'thank you'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mflag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ROBO: you are welcome\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'user_resonse' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGhYSWKT5XII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jf19Jsa85cAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ew7eS7so5r5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':\"1ShGidDG1N50IcRinK1G-4YPSKgi35DZJ\"})   # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('ChatBotQueries.txt')        # replace the file name with your file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zwb_zvT5wVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "data = open('ChatBotQueries.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3Jx5CAj6NQC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "1538cd4f-c353-42c5-84d8-b39b100312ea"
      },
      "source": [
        "from nltk.chat.util import Chat, reflections\n",
        "pairs = [\n",
        "    [\n",
        "        r\"my name is (.*)\",\n",
        "        [\"Hello %1, How are you today ?\",]\n",
        "    ],\n",
        "     [\n",
        "        r\"what is your name ?\",\n",
        "        [\"My name is Chatty and I'm a chatbot ?\",]\n",
        "    ],\n",
        "    [\n",
        "        r\"how are you ?\",\n",
        "        [\"I'm doing good\\nHow about You ?\",]\n",
        "    ],\n",
        "    [\n",
        "        r\"sorry (.*)\",\n",
        "        [\"Its alright\",\"Its OK, never mind\",]\n",
        "    ],\n",
        "    [\n",
        "        r\"i'm (.*) doing good\",\n",
        "        [\"Nice to hear that\",\"Alright :)\",]\n",
        "    ],\n",
        "    [\n",
        "        r\"hi|hey|hello\",\n",
        "        [\"Hello\", \"Hey there\",]\n",
        "    ],\n",
        "    [\n",
        "        r\"(.*) age?\",\n",
        "        [\"I'm a computer program dude\\nSeriously you are asking me this?\",]\n",
        "        \n",
        "    ],\n",
        "    [\n",
        "        r\"what (.*) want ?\",\n",
        "        [\"Make me an offer I can't refuse\",]\n",
        "        \n",
        "    ],\n",
        "    [\n",
        "        r\"(.*) created ?\",\n",
        "        [\"Nagesh created me using Python's NLTK library \",\"top secret ;)\",]\n",
        "    ],\n",
        "    [\n",
        "        r\"(.*) (location|city) ?\",\n",
        "        ['Chennai, Tamil Nadu',]\n",
        "    ],\n",
        "    [\n",
        "        r\"how is weather in (.*)?\",\n",
        "        [\"Weather in %1 is awesome like always\",\"Too hot man here in %1\",\"Too cold man here in %1\",\"Never even heard about %1\"]\n",
        "    ],\n",
        "    [\n",
        "        r\"i work in (.*)?\",\n",
        "        [\"%1 is an Amazing company, I have heard about it. But they are in huge loss these days.\",]\n",
        "    ],\n",
        "[\n",
        "        r\"(.*)raining in (.*)\",\n",
        "        [\"No rain since last week here in %2\",\"Damn its raining too much here in %2\"]\n",
        "    ],\n",
        "    [\n",
        "        r\"how (.*) health(.*)\",\n",
        "        [\"I'm a computer program, so I'm always healthy \",]\n",
        "    ],\n",
        "    [\n",
        "        r\"(.*) (sports|game) ?\",\n",
        "        [\"I'm a very big fan of Football\",]\n",
        "    ],\n",
        "    [\n",
        "        r\"who (.*) sportsperson ?\",\n",
        "        [\"Messy\",\"Ronaldo\",\"Roony\"]\n",
        "],\n",
        "    [\n",
        "        r\"who (.*) (moviestar|actor)?\",\n",
        "        [\"Brad Pitt\"]\n",
        "],\n",
        "    [\n",
        "        r\"quit\",\n",
        "        [\"BBye take care. See you soon :) \",\"It was nice talking to you. See you soon :)\"]\n",
        "],\n",
        "]\n",
        "def chatty():\n",
        "        print(\"Hi, I'm Chatty and I chat alot ;)\\nPlease type lowercase English language to start a conversation. Type quit to leave \")\n",
        "        chat = Chat(pairs, reflections)\n",
        "        chat.converse()\n",
        "        print(input(\"Enter choice\"))\n",
        "if __name__ == \"__main__\":\n",
        "    chatty()"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hi, I'm Chatty and I chat alot ;)\n",
            "Please type lowercase English language to start a conversation. Type quit to leave \n",
            ">quit\n",
            "It was nice talking to you. See you soon :)\n",
            "Enter choicesports\n",
            "sports\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}